{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e997539",
   "metadata": {},
   "source": [
    "# Gemini (Vertex AI) — Auto schema discovery + schema‑constrained JSON extraction (PDF)\n",
    "\n",
    "This notebook implements an **LLM‑native** pipeline using **only Gemini** (no PDF parsers like pdfplumber/camelot/tabula):\n",
    "\n",
    "1) **Schema discovery**: Gemini reads the PDF and *induces* an optimal JSON schema/hierarchy for the document  \n",
    "2) **Extraction**: Gemini extracts the document into that schema using **Structured Outputs** (`response_schema`)  \n",
    "3) **Validation & persistence**: Validate the extracted JSON against the discovered schema and save artifacts\n",
    "\n",
    "✅ Designed to be flexible across different PDF layouts (text + tables + numeric data).  \n",
    "✅ Works with **Vertex AI** (`vertexai=True`) using ADC credentials (no API key in code).  \n",
    "✅ Uses `model = \"gemini-2.5-pro\"`, `temperature = 0`.\n",
    "\n",
    "> **Auth prerequisites (Vertex AI / ADC)**  \n",
    "> - Either set `GOOGLE_APPLICATION_CREDENTIALS` in your `.env` to a service account JSON  \n",
    "> - or run `gcloud auth application-default login` in your environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U google-genai jsonschema python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7dc86b",
   "metadata": {},
   "source": [
    "## 0) Setup: environment + Vertex AI Gemini client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3137935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "import os, json, hashlib\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple, Optional, List\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from jsonschema import validate\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL = \"gemini-2.5-pro\"\n",
    "PROJECT = \"\"\n",
    "LOCATION = \"\"\n",
    "TEMPERATURE = 0\n",
    "\n",
    "# Vertex AI client (no API key passed explicitly)\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=PROJECT,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "def sha256_file(path: str) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4380279",
   "metadata": {},
   "source": [
    "## 1) Helpers (no PDF parsing — only bytes/URI inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdf_part(path_or_gcs_uri: str) -> types.Part:\n",
    "    \"\"\"Create a Gemini input Part for a PDF.\n",
    "    - If gs:// URI: uses from_uri\n",
    "    - Else: reads local bytes and uses from_bytes\n",
    "    \"\"\"\n",
    "    if path_or_gcs_uri.startswith(\"gs://\"):\n",
    "        return types.Part.from_uri(path_or_gcs_uri, mime_type=\"application/pdf\")\n",
    "    data = Path(path_or_gcs_uri).read_bytes()\n",
    "    # Use keyword arguments for maximum compatibility across SDK versions\n",
    "    return types.Part.from_bytes(data=data, mime_type=\"application/pdf\")\n",
    "\n",
    "FORBIDDEN_SCHEMA_KEYS = {\n",
    "    \"$schema\", \"$id\", \"$defs\", \"$ref\", \"definitions\"\n",
    "}\n",
    "FORBIDDEN_SCHEMA_CONSTRUCTS = {\n",
    "    \"oneOf\", \"anyOf\", \"allOf\", \"patternProperties\", \"dependentSchemas\"\n",
    "}\n",
    "\n",
    "def sanitize_vertex_schema(schema: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Remove JSON-Schema meta/ref features that Vertex structured outputs may reject.\"\"\"\n",
    "    def _clean(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            out = {}\n",
    "            for k, v in obj.items():\n",
    "                if k in FORBIDDEN_SCHEMA_KEYS:\n",
    "                    continue\n",
    "                if k in FORBIDDEN_SCHEMA_CONSTRUCTS:\n",
    "                    # Drop unsupported constructs rather than fail fast.\n",
    "                    # You can choose to raise instead if you prefer.\n",
    "                    continue\n",
    "                if k.startswith(\"$\"):\n",
    "                    continue\n",
    "                out[k] = _clean(v)\n",
    "            return out\n",
    "        if isinstance(obj, list):\n",
    "            return [_clean(x) for x in obj]\n",
    "        return obj\n",
    "\n",
    "    cleaned = _clean(schema)\n",
    "\n",
    "    # Ensure minimal sane top-level\n",
    "    if \"type\" not in cleaned:\n",
    "        cleaned[\"type\"] = \"object\"\n",
    "    if \"additionalProperties\" not in cleaned:\n",
    "        cleaned[\"additionalProperties\"] = True\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def safe_json_load(s: str) -> Any:\n",
    "    \"\"\"Parse JSON robustly; structured outputs should already be valid JSON.\"\"\"\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        # Try extracting the first {...} block\n",
    "        start = s.find(\"{\")\n",
    "        end = s.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            return json.loads(s[start:end+1])\n",
    "        raise\n",
    "\n",
    "def save_json(obj: Any, path: str) -> None:\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c3c15",
   "metadata": {},
   "source": [
    "## 2) Define a **meta‑schema** for the schema discovery step\n",
    "\n",
    "We use Structured Outputs to force Gemini to return a **Schema Plan** JSON object with:\n",
    "- `document_profile`: high-level structure signals\n",
    "- `schema`: a **Vertex‑safe JSON schema** (no `$schema`, `$ref`, `$defs`, etc.)\n",
    "- `system_instruction`: tailored extraction rules to use in the next step\n",
    "\n",
    "This keeps schema discovery deterministic and machine‑readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14504b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_PLAN_SCHEMA: Dict[str, Any] = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"required\": [\"document_profile\", \"schema\", \"system_instruction\"],\n",
    "    \"properties\": {\n",
    "        \"document_profile\": {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"required\": [\"title_guess\", \"structure_style\", \"tables_present\", \"numbering_style\"],\n",
    "            \"properties\": {\n",
    "                \"title_guess\": {\"type\": \"string\"},\n",
    "                \"structure_style\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"e.g., 'numbered_sections', 'headings', 'freeform_blocks'\",\n",
    "                    \"enum\": [\"numbered_sections\", \"headings\", \"freeform_blocks\", \"mixed\"]\n",
    "                },\n",
    "                \"tables_present\": {\"type\": \"boolean\"},\n",
    "                \"numbering_style\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"e.g., '1/1.1', 'A/B', 'none'\",\n",
    "                },\n",
    "                \"notes\": {\"type\": \"string\"},\n",
    "            },\n",
    "        },\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"description\": \"Vertex-safe JSON schema to use for extraction (no $schema/$ref/$defs).\",\n",
    "            \"additionalProperties\": True\n",
    "        },\n",
    "        \"system_instruction\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"System instruction to use during extraction.\"\n",
    "        },\n",
    "        \"extraction_prompt\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Optional user prompt to use during extraction.\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "SCHEMA_PLAN_SCHEMA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef837dbd",
   "metadata": {},
   "source": [
    "## 3) Step 1 — Schema discovery (Gemini reads the PDF and proposes the best hierarchy)\n",
    "\n",
    "**Important constraints (enforced in the prompt):**\n",
    "- Do NOT use `$schema`, `$ref`, `$defs`\n",
    "- Keep the schema **generic enough** to fit similar documents\n",
    "- Prefer a clean hierarchy: `metadata` + `sections[]` + optional `subsections[]`\n",
    "- Represent tables in a consistent way: `columns[]` + `rows[]` (rows as objects)\n",
    "\n",
    "> You can reuse a discovered schema across many reports if they share the same format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"/mnt/data/Report - Sample.pdf\"  # change to your PDF path or gs:// URI\n",
    "pdf_part = make_pdf_part(PDF_PATH)\n",
    "\n",
    "schema_discovery_system = \"\"\"You are a schema induction engine for business reports.\n",
    "Your job: read the provided PDF and propose an optimal JSON schema that represents the document's content and hierarchy.\n",
    "\n",
    "Hard constraints for the schema you output:\n",
    "- Output MUST be valid JSON.\n",
    "- The schema MUST be Vertex-safe:\n",
    "  - DO NOT use $schema, $id, $defs, $ref, definitions\n",
    "  - DO NOT use oneOf/anyOf/allOf, patternProperties, dependentSchemas\n",
    "  - Use only: type, properties, required, items, enum, additionalProperties, description\n",
    "- The schema MUST be flexible for similar PDFs:\n",
    "  - Use arrays for repeating structures (sections/subsections)\n",
    "  - Use a generic table representation: {title, kind, columns, rows}\n",
    "  - Include a citations field with page numbers for traceability.\n",
    "\n",
    "Optimization goals:\n",
    "- Discover a natural hierarchy (metadata → sections → subsections).\n",
    "- If the doc has numbered headings, capture those numbers.\n",
    "- If the doc has key/value tables, represent them as kind='kv_pairs'.\n",
    "- If the doc has matrix tables, represent them as kind='matrix'.\n",
    "\n",
    "Return a Schema Plan that conforms to the provided Schema Plan schema.\n",
    "\"\"\"\n",
    "\n",
    "schema_discovery_user = \"\"\"Analyze this PDF and generate a Schema Plan for extracting it into JSON.\n",
    "Your schema should represent the best hierarchy you can infer from the document.\"\"\"\n",
    "\n",
    "resp_plan = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=[pdf_part, schema_discovery_user],   # NOTE: plain string (no Part.from_text)\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=schema_discovery_system,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=SCHEMA_PLAN_SCHEMA,\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "schema_plan = safe_json_load(resp_plan.text)\n",
    "\n",
    "# sanitize the returned schema to be safe for Vertex structured outputs\n",
    "schema_plan[\"schema\"] = sanitize_vertex_schema(schema_plan[\"schema\"])\n",
    "\n",
    "schema_plan[\"document_profile\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a003afc",
   "metadata": {},
   "source": [
    "## 4) Step 2 — Schema‑constrained extraction using the discovered schema\n",
    "\n",
    "We now call Gemini again with:\n",
    "- `response_schema = schema_plan[\"schema\"]`\n",
    "- `response_mime_type = \"application/json\"`\n",
    "- `system_instruction` tuned for the discovered structure\n",
    "\n",
    "No external PDF parsing is performed; Gemini reads the PDF directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_system = schema_plan[\"system_instruction\"]\n",
    "\n",
    "# If the plan included a preferred extraction prompt, use it; else default.\n",
    "extraction_user = schema_plan.get(\"extraction_prompt\") or \"Extract this document into the provided JSON schema.\"\n",
    "\n",
    "resp_data = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=[pdf_part, extraction_user],  # plain string again\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=extraction_system,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=schema_plan[\"schema\"],\n",
    "        temperature=TEMPERATURE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "extracted = safe_json_load(resp_data.text)\n",
    "list(extracted.keys()) if isinstance(extracted, dict) else type(extracted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc09572",
   "metadata": {},
   "source": [
    "## 5) Validate and save outputs\n",
    "\n",
    "We validate the extracted JSON using `jsonschema.validate` against the discovered schema.\n",
    "\n",
    "Then we save:\n",
    "- `schema_plan.json`\n",
    "- `extracted.json`\n",
    "\n",
    "> If validation fails in some documents, you can add an automatic \"repair\" step by calling Gemini with the validation error and asking it to re-output JSON conforming to the same schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate extracted JSON against the discovered schema\n",
    "validate(instance=extracted, schema=schema_plan[\"schema\"])\n",
    "\n",
    "out_dir = \"/mnt/data/gemini_auto_schema_outputs\"\n",
    "report_id = Path(PDF_PATH).stem\n",
    "report_hash = sha256_file(PDF_PATH) if not PDF_PATH.startswith(\"gs://\") else \"gcs_uri\"\n",
    "\n",
    "plan_path = str(Path(out_dir) / f\"{report_id}.schema_plan.json\")\n",
    "data_path = str(Path(out_dir) / f\"{report_id}.extracted.json\")\n",
    "\n",
    "save_json(schema_plan, plan_path)\n",
    "save_json(extracted, data_path)\n",
    "\n",
    "plan_path, data_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f02a0a",
   "metadata": {},
   "source": [
    "## 6) Optional: automatic repair on validation failure (Gemini-only)\n",
    "\n",
    "If `jsonschema.validate(...)` raises an error, you can ask Gemini to **repair** the JSON.\n",
    "\n",
    "This is helpful when the model:\n",
    "- forgets a required field\n",
    "- returns a value with the wrong type\n",
    "- adds unexpected keys\n",
    "\n",
    "The function below retries once with the validation error context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema.exceptions import ValidationError\n",
    "\n",
    "def repair_to_schema(pdf_part: types.Part, schema: Dict[str, Any], extraction_system: str, bad_json: Any, error: Exception) -> Any:\n",
    "    repair_system = \"\"\"You are a JSON repair engine.\n",
    "You MUST output JSON that conforms to the provided schema.\n",
    "Do not add commentary. Do not wrap JSON in markdown.\n",
    "\"\"\"\n",
    "\n",
    "    repair_user = f\"\"\"The previous extraction did not validate against the schema.\n",
    "\n",
    "Validation error:\n",
    "{str(error)}\n",
    "\n",
    "Here is the invalid JSON (may be incomplete):\n",
    "{json.dumps(bad_json, indent=2)[:8000]}\n",
    "\n",
    "Re-extract/repair by reading the PDF again and output ONLY corrected JSON that conforms to the schema.\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[pdf_part, repair_user],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=repair_system + \"\\n\\n\" + extraction_system,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=schema,\n",
    "            temperature=0,\n",
    "        ),\n",
    "    )\n",
    "    return safe_json_load(resp.text)\n",
    "\n",
    "# Example usage:\n",
    "# try:\n",
    "#     validate(instance=extracted, schema=schema_plan[\"schema\"])\n",
    "# except ValidationError as e:\n",
    "#     extracted = repair_to_schema(pdf_part, schema_plan[\"schema\"], extraction_system, extracted, e)\n",
    "#     validate(instance=extracted, schema=schema_plan[\"schema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217931d6",
   "metadata": {},
   "source": [
    "## 7) Batch processing (many PDFs)\n",
    "\n",
    "Two modes:\n",
    "- `reuse_schema=True`: discover schema from the **first** PDF, reuse for the rest (fast, great for periodic reports)\n",
    "- `reuse_schema=False`: discover a new schema **per PDF** (flexible for mixed document types)\n",
    "\n",
    "Still **Gemini-only** (no PDF parsers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef403e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_schema_plan(pdf_part: types.Part) -> Dict[str, Any]:\n",
    "    resp_plan = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[pdf_part, schema_discovery_user],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=schema_discovery_system,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=SCHEMA_PLAN_SCHEMA,\n",
    "            temperature=0,\n",
    "        ),\n",
    "    )\n",
    "    plan = safe_json_load(resp_plan.text)\n",
    "    plan[\"schema\"] = sanitize_vertex_schema(plan[\"schema\"])\n",
    "    return plan\n",
    "\n",
    "def extract_with_plan(pdf_part: types.Part, plan: Dict[str, Any]) -> Any:\n",
    "    extraction_system = plan[\"system_instruction\"]\n",
    "    extraction_user = plan.get(\"extraction_prompt\") or \"Extract this document into the provided JSON schema.\"\n",
    "    resp = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[pdf_part, extraction_user],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=extraction_system,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=plan[\"schema\"],\n",
    "            temperature=TEMPERATURE,\n",
    "        ),\n",
    "    )\n",
    "    return safe_json_load(resp.text)\n",
    "\n",
    "def process_pdfs(pdf_paths: List[str], out_dir: str, reuse_schema: bool = True) -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"Returns list of (pdf_path, schema_plan_path, extracted_path).\"\"\"\n",
    "    results = []\n",
    "    plan = None\n",
    "\n",
    "    for i, pdf_path in enumerate(tqdm(pdf_paths)):\n",
    "        pdf_part = make_pdf_part(pdf_path)\n",
    "\n",
    "        if (plan is None) or (not reuse_schema):\n",
    "            plan = discover_schema_plan(pdf_part)\n",
    "\n",
    "        extracted = extract_with_plan(pdf_part, plan)\n",
    "\n",
    "        # Validate; if fails, repair once\n",
    "        try:\n",
    "            validate(instance=extracted, schema=plan[\"schema\"])\n",
    "        except Exception as e:\n",
    "            extracted = repair_to_schema(pdf_part, plan[\"schema\"], plan[\"system_instruction\"], extracted, e)\n",
    "            validate(instance=extracted, schema=plan[\"schema\"])\n",
    "\n",
    "        rid = Path(pdf_path).stem\n",
    "        plan_path = str(Path(out_dir) / f\"{rid}.schema_plan.json\")\n",
    "        data_path = str(Path(out_dir) / f\"{rid}.extracted.json\")\n",
    "        save_json(plan, plan_path)\n",
    "        save_json(extracted, data_path)\n",
    "\n",
    "        results.append((pdf_path, plan_path, data_path))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example:\n",
    "# pdfs = [\"/path/to/r1.pdf\", \"/path/to/r2.pdf\"]\n",
    "# results = process_pdfs(pdfs, out_dir=\"/path/to/out\", reuse_schema=True)\n",
    "# results[:2]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
